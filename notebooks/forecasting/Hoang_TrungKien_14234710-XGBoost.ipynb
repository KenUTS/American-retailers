{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQ6wc2HE0pke"
   },
   "source": [
    "# **Assignment 2:**\n",
    "\n",
    "Forecasting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_OzElWylM3Y"
   },
   "source": [
    "## The steps are:\n",
    "1.   Load and explore dataset\n",
    "2.   Data preparation\n",
    "3.   Split data\n",
    "4.   ARIMA model¶\n",
    "5.   XGBoost model with hyperparamaters¶\n",
    "6.   XGBoost model with optimal hyperparamaters and lags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3IwbDesTs-dr",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1. Load and explore dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qMQmbGW_tKJ-",
    "tags": []
   },
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2vRVBbfjtOhU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzT7km_-tTKZ"
   },
   "source": [
    "Load the dataset into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../../data/raw/sales_test.csv')\n",
    "df_train = pd.read_csv('../../data/raw/sales_train.csv')\n",
    "df_events = pd.read_csv('../../data/raw/calendar_events.csv')\n",
    "df_calendar = pd.read_csv('../../data/raw/calendar.csv')\n",
    "df_items_weekly_price = pd.read_csv('../../data/raw/items_weekly_sell_prices.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_LcXROJtzuB"
   },
   "source": [
    "Display the first 5 rows of tranining data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "UQCI2nkSK_Cw",
    "outputId": "9512e90f-bcf8-4293-ccc7-a78a9b80eebb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1532</th>\n",
       "      <th>d_1533</th>\n",
       "      <th>d_1534</th>\n",
       "      <th>d_1535</th>\n",
       "      <th>d_1536</th>\n",
       "      <th>d_1537</th>\n",
       "      <th>d_1538</th>\n",
       "      <th>d_1539</th>\n",
       "      <th>d_1540</th>\n",
       "      <th>d_1541</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1547 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id   \n",
       "0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1  \\\n",
       "1  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id  d_1  d_2  d_3  d_4  ...  d_1532  d_1533  d_1534  d_1535  d_1536   \n",
       "0       CA    0    0    0    0  ...       1       1       1       0       1  \\\n",
       "1       CA    0    0    0    0  ...       0       0       0       0       0   \n",
       "2       CA    0    0    0    0  ...       0       0       1       0       0   \n",
       "3       CA    0    0    0    0  ...       8       2       0       8       2   \n",
       "4       CA    0    0    0    0  ...       2       0       1       3       2   \n",
       "\n",
       "   d_1537  d_1538  d_1539  d_1540  d_1541  \n",
       "0       0       1       0       0       1  \n",
       "1       0       0       0       1       0  \n",
       "2       0       0       0       0       0  \n",
       "3       3       1       1       3       8  \n",
       "4       1       1       2       2       3  \n",
       "\n",
       "[5 rows x 1547 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in tranining data:\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values in tranining data:\")\n",
    "for i in df_train.columns[df_train.isna().any()]:\n",
    "    no_missing = df_train[i].isna().sum()\n",
    "    print(\"Column \"+str(i) +\":\"+str(no_missing) +\" NAs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information of training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30490 entries, 0 to 30489\n",
      "Columns: 1547 entries, id to d_1541\n",
      "dtypes: int64(1541), object(6)\n",
      "memory usage: 359.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing first 5 rows of calendar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>d_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>d_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>11101</td>\n",
       "      <td>d_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>11101</td>\n",
       "      <td>d_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>11101</td>\n",
       "      <td>d_5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  wm_yr_wk    d\n",
       "0  2011-01-29     11101  d_1\n",
       "1  2011-01-30     11101  d_2\n",
       "2  2011-01-31     11101  d_3\n",
       "3  2011-02-01     11101  d_4\n",
       "4  2011-02-02     11101  d_5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_calendar.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing first 5 rows of event calendar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>event_name</th>\n",
       "      <th>event_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-02-06</td>\n",
       "      <td>SuperBowl</td>\n",
       "      <td>Sporting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-02-14</td>\n",
       "      <td>ValentinesDay</td>\n",
       "      <td>Cultural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-02-21</td>\n",
       "      <td>PresidentsDay</td>\n",
       "      <td>National</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-03-09</td>\n",
       "      <td>LentStart</td>\n",
       "      <td>Religious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-03-16</td>\n",
       "      <td>LentWeek2</td>\n",
       "      <td>Religious</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     event_name event_type\n",
       "0  2011-02-06      SuperBowl   Sporting\n",
       "1  2011-02-14  ValentinesDay   Cultural\n",
       "2  2011-02-21  PresidentsDay   National\n",
       "3  2011-03-09      LentStart  Religious\n",
       "4  2011-03-16      LentWeek2  Religious"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing first 5 rows of test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_1542</th>\n",
       "      <th>d_1543</th>\n",
       "      <th>d_1544</th>\n",
       "      <th>d_1545</th>\n",
       "      <th>d_1546</th>\n",
       "      <th>d_1547</th>\n",
       "      <th>d_1548</th>\n",
       "      <th>d_1549</th>\n",
       "      <th>d_1550</th>\n",
       "      <th>d_1551</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1932</th>\n",
       "      <th>d_1933</th>\n",
       "      <th>d_1934</th>\n",
       "      <th>d_1935</th>\n",
       "      <th>d_1936</th>\n",
       "      <th>d_1937</th>\n",
       "      <th>d_1938</th>\n",
       "      <th>d_1939</th>\n",
       "      <th>d_1940</th>\n",
       "      <th>d_1941</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   d_1542  d_1543  d_1544  d_1545  d_1546  d_1547  d_1548  d_1549  d_1550   \n",
       "0       0       1       0       2       1       0       2       0       1  \\\n",
       "1       0       0       0       0       0       0       0       0       1   \n",
       "2       0       0       0       0       0       1       0       0       0   \n",
       "3       4       1       0       1       3       5       2       3       0   \n",
       "4       3       0       0       1       1       0       2       0       2   \n",
       "\n",
       "   d_1551  ...  d_1932  d_1933  d_1934  d_1935  d_1936  d_1937  d_1938   \n",
       "0       0  ...       2       4       0       0       0       0       3  \\\n",
       "1       0  ...       0       1       2       1       1       0       0   \n",
       "2       0  ...       1       0       2       0       0       0       2   \n",
       "3       2  ...       1       1       0       4       0       1       3   \n",
       "4       1  ...       0       0       0       2       1       0       0   \n",
       "\n",
       "   d_1939  d_1940  d_1941  \n",
       "0       3       0       1  \n",
       "1       0       0       0  \n",
       "2       3       0       1  \n",
       "3       0       2       6  \n",
       "4       2       1       0  \n",
       "\n",
       "[5 rows x 400 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Data preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melt the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnns=['id','dept_id','cat_id','state_id']\n",
    "df_train_melt=pd.melt(df_train.drop(columns=columnns),id_vars=['item_id','store_id'],var_name='day',value_name='sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>day</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id store_id  day  sales\n",
       "0  HOBBIES_1_001     CA_1  d_1      0\n",
       "1  HOBBIES_1_002     CA_1  d_1      0\n",
       "2  HOBBIES_1_003     CA_1  d_1      0\n",
       "3  HOBBIES_1_004     CA_1  d_1      0\n",
       "4  HOBBIES_1_005     CA_1  d_1      0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_melt.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining calendar and events datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ce = pd.merge(df_calendar, df_events, on='date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#drop the event name\n",
    "df_ce.drop(columns=\"event_name\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Rename day\n",
    "df_ce.rename(columns={'d':'day'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "df_ce.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One date can have multiple events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date  wm_yr_wk     day event_type\n",
      "86    2011-04-24     11113    d_86  Religious\n",
      "829   2013-05-05     11315   d_828  Religious\n",
      "1180  2014-04-20     11412  d_1178  Religious\n",
      "1237  2014-06-15     11420  d_1234   Sporting\n",
      "1973  2016-06-19     11621  d_1969   Sporting\n"
     ]
    }
   ],
   "source": [
    "print(df_ce[df_ce.duplicated('day')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>day</th>\n",
       "      <th>event_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2011-04-24</td>\n",
       "      <td>11113</td>\n",
       "      <td>d_86</td>\n",
       "      <td>Cultural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2011-04-24</td>\n",
       "      <td>11113</td>\n",
       "      <td>d_86</td>\n",
       "      <td>Religious</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  wm_yr_wk   day event_type\n",
       "85  2011-04-24     11113  d_86   Cultural\n",
       "86  2011-04-24     11113  d_86  Religious"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ce[df_ce[\"day\"]==\"d_86\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the malted dataset vs combined calendar and event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_ce = pd.merge(df_train_melt, df_ce, on='day', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine with items weekly price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_combined = pd.merge(df_train_ce, df_items_weekly_price, on=['item_id','store_id','wm_yr_wk'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>day</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>event_type</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id store_id  day  sales        date  wm_yr_wk event_type   \n",
       "0  HOBBIES_1_001     CA_1  d_1      0  2011-01-29     11101        NaN  \\\n",
       "1  HOBBIES_1_002     CA_1  d_1      0  2011-01-29     11101        NaN   \n",
       "2  HOBBIES_1_003     CA_1  d_1      0  2011-01-29     11101        NaN   \n",
       "3  HOBBIES_1_004     CA_1  d_1      0  2011-01-29     11101        NaN   \n",
       "4  HOBBIES_1_005     CA_1  d_1      0  2011-01-29     11101        NaN   \n",
       "\n",
       "   sell_price  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_combined.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in tranining data:\n",
      "Column event_type:43143350 NAs\n",
      "Column sell_price:12291876 NAs\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values in tranining data:\")\n",
    "for i in df_train_combined.columns[df_train_combined.isna().any()]:\n",
    "    no_missing = df_train_combined[i].isna().sum()\n",
    "    print(\"Column \"+str(i) +\":\"+str(no_missing) +\" NAs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Fill null values in weekly sell price with average prices of the same item in different stores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_price = df_train_combined.groupby(['item_id'])['sell_price'].transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_combined['sell_price'].fillna(mean_price, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a revanue column by using sales and sell_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_combined[\"revenue\"]=df_train_combined[\"sales\"]*df_train_combined[\"sell_price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a event columns to check if is there event on this day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_combined['is_event'] = df_train_combined['event_type'].notnull().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop sale, day, wm_yr_wk,sell_price, event_type columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_combined.drop(columns=[\"item_id\",\"store_id\",\"day\",\"event_type\",\"sales\",\"wm_yr_wk\",\"sell_price\"],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert date to timestampe and then create new columns as day of month, month of year and day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_combined['date'] = pd.to_datetime(df_train_combined['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>is_event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>81650.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>78970.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>57706.91</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>60761.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>46959.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>2015-04-14</td>\n",
       "      <td>102896.92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>2015-04-15</td>\n",
       "      <td>106913.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>2015-04-16</td>\n",
       "      <td>98373.49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>2015-04-17</td>\n",
       "      <td>103030.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>2015-04-18</td>\n",
       "      <td>132625.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1541 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date    revenue  is_event\n",
       "0    2011-01-29   81650.61         0\n",
       "1    2011-01-30   78970.57         0\n",
       "2    2011-01-31   57706.91         0\n",
       "3    2011-02-01   60761.20         0\n",
       "4    2011-02-02   46959.95         0\n",
       "...         ...        ...       ...\n",
       "1536 2015-04-14  102896.92         0\n",
       "1537 2015-04-15  106913.88         0\n",
       "1538 2015-04-16   98373.49         0\n",
       "1539 2015-04-17  103030.58         0\n",
       "1540 2015-04-18  132625.89         0\n",
       "\n",
       "[1541 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_grouped = df_train_combined.groupby('date').agg({'revenue': 'sum', 'is_event': 'max'}).reset_index()\n",
    "df_train_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQvGUYHjpdIc",
    "tags": []
   },
   "source": [
    "## 3. Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_cleaned = df_train_grouped.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_cleaned['lag_1'] = df_cleaned['revenue'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting dataset to training and validating dataset with ratio 8:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = int(len(df_cleaned) * 0.8)\n",
    "train_data = df_cleaned.iloc[:index]\n",
    "valid_data = df_cleaned.iloc[index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1232, 4)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 4)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NCwQQFkU3v5",
    "tags": []
   },
   "source": [
    "## 4. ARIMA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fbprophet\n",
      "  Downloading fbprophet-0.7.1.tar.gz (64 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m274.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting Cython>=0.22 (from fbprophet)\n",
      "  Downloading Cython-3.0.2-cp39-cp39-macosx_10_9_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m0m\n",
      "\u001b[?25hCollecting cmdstanpy==0.9.5 (from fbprophet)\n",
      "  Downloading cmdstanpy-0.9.5-py3-none-any.whl (37 kB)\n",
      "Collecting pystan>=2.14 (from fbprophet)\n",
      "  Downloading pystan-3.7.0-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages (from fbprophet) (1.25.2)\n",
      "Requirement already satisfied: pandas>=1.0.4 in /Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages (from fbprophet) (2.0.1)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages (from fbprophet) (3.8.0)\n",
      "Requirement already satisfied: LunarCalendar>=0.0.9 in /Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages (from fbprophet) (0.0.9)\n",
      "Requirement already satisfied: convertdate>=2.1.2 in /Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages (from fbprophet) (2.4.0)\n",
      "Requirement already satisfied: holidays>=0.10.2 in /Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages (from fbprophet) (0.34)\n",
      "Collecting setuptools-git>=1.2 (from fbprophet)\n",
      "  Downloading setuptools_git-1.2-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages (from fbprophet) (2.8.2)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in /Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages (from fbprophet) (4.66.1)\n",
      "Requirement already satisfied: pymeeus<=1,>=0.3.13 in /Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages (from convertdate>=2.1.2->fbprophet) (0.5.12)\n",
      "Requirement already satisfied: ephem>=3.7.5.3 in /Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages (from LunarCalendar>=0.0.9->fbprophet) (4.1.4)\n",
      "Requirement already satisfied: pytz in /Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages (from LunarCalendar>=0.0.9->fbprophet) (2023.3.post1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages (from matplotlib>=2.0.0->fbprophet) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages (from matplotlib>=2.0.0->fbprophet) (0.12.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages (from matplotlib>=2.0.0->fbprophet) (4.43.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages (from matplotlib>=2.0.0->fbprophet) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages (from matplotlib>=2.0.0->fbprophet) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages (from matplotlib>=2.0.0->fbprophet) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages (from matplotlib>=2.0.0->fbprophet) (3.1.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages (from matplotlib>=2.0.0->fbprophet) (6.1.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages (from pandas>=1.0.4->fbprophet) (2023.3)\n",
      "Collecting aiohttp<4.0,>=3.6 (from pystan>=2.14->fbprophet)\n",
      "  Downloading aiohttp-3.8.5-cp39-cp39-macosx_10_9_x86_64.whl (368 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m368.1/368.1 kB\u001b[0m \u001b[31m997.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting clikit<0.7,>=0.6 (from pystan>=2.14->fbprophet)\n",
      "  Downloading clikit-0.6.2-py2.py3-none-any.whl (91 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m830.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting httpstan<4.11,>=4.10 (from pystan>=2.14->fbprophet)\n",
      "  Downloading httpstan-4.10.1-cp39-cp39-macosx_10_16_x86_64.whl (35.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.8/35.8 MB\u001b[0m \u001b[31m513.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hCollecting pysimdjson<6.0.0,>=5.0.2 (from pystan>=2.14->fbprophet)\n",
      "  Downloading pysimdjson-5.0.2-cp39-cp39-macosx_10_9_x86_64.whl (195 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.5/195.5 kB\u001b[0m \u001b[31m798.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages (from pystan>=2.14->fbprophet) (67.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.0->fbprophet) (1.16.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages (from aiohttp<4.0,>=3.6->pystan>=2.14->fbprophet) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages (from aiohttp<4.0,>=3.6->pystan>=2.14->fbprophet) (3.3.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0,>=3.6->pystan>=2.14->fbprophet)\n",
      "  Downloading multidict-6.0.4-cp39-cp39-macosx_10_9_x86_64.whl (29 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3 (from aiohttp<4.0,>=3.6->pystan>=2.14->fbprophet)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0,>=3.6->pystan>=2.14->fbprophet)\n",
      "  Downloading yarl-1.9.2-cp39-cp39-macosx_10_9_x86_64.whl (65 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m459.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp<4.0,>=3.6->pystan>=2.14->fbprophet)\n",
      "  Downloading frozenlist-1.4.0-cp39-cp39-macosx_10_9_x86_64.whl (47 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 kB\u001b[0m \u001b[31m401.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp<4.0,>=3.6->pystan>=2.14->fbprophet)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting crashtest<0.4.0,>=0.3.0 (from clikit<0.7,>=0.6->pystan>=2.14->fbprophet)\n",
      "  Downloading crashtest-0.3.1-py3-none-any.whl (7.0 kB)\n",
      "Collecting pastel<0.3.0,>=0.2.0 (from clikit<0.7,>=0.6->pystan>=2.14->fbprophet)\n",
      "  Downloading pastel-0.2.1-py2.py3-none-any.whl (6.0 kB)\n",
      "Collecting pylev<2.0,>=1.3 (from clikit<0.7,>=0.6->pystan>=2.14->fbprophet)\n",
      "  Downloading pylev-1.4.0-py2.py3-none-any.whl (6.1 kB)\n",
      "Collecting appdirs<2.0,>=1.4 (from httpstan<4.11,>=4.10->pystan>=2.14->fbprophet)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting marshmallow<4.0,>=3.10 (from httpstan<4.11,>=4.10->pystan>=2.14->fbprophet)\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m654.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting webargs<9.0,>=8.0 (from httpstan<4.11,>=4.10->pystan>=2.14->fbprophet)\n",
      "  Downloading webargs-8.3.0-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib>=2.0.0->fbprophet) (3.17.0)\n",
      "Requirement already satisfied: idna>=2.0 in /Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages (from yarl<2.0,>=1.0->aiohttp<4.0,>=3.6->pystan>=2.14->fbprophet) (3.4)\n",
      "Building wheels for collected packages: fbprophet\n",
      "  Building wheel for fbprophet (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[55 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib\n",
      "  \u001b[31m   \u001b[0m creating build/lib/fbprophet\n",
      "  \u001b[31m   \u001b[0m creating build/lib/fbprophet/stan_model\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/53/lfhrj5t92lb1ltnby1j6jf000000gn/T/pip-install-jzutxkvv/fbprophet_1834d5c075da4a35a78c5eeb078fa960/setup.py\", line 122, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup(\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages/setuptools/__init__.py\", line 108, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages/setuptools/_distutils/core.py\", line 185, in setup\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages/setuptools/_distutils/core.py\", line 201, in run_commands\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 969, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages/setuptools/dist.py\", line 1221, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages/wheel/bdist_wheel.py\", line 343, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(\"build\")\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages/setuptools/_distutils/cmd.py\", line 318, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages/setuptools/dist.py\", line 1221, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages/setuptools/_distutils/command/build.py\", line 131, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd_name)\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages/setuptools/_distutils/cmd.py\", line 318, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages/setuptools/dist.py\", line 1221, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/53/lfhrj5t92lb1ltnby1j6jf000000gn/T/pip-install-jzutxkvv/fbprophet_1834d5c075da4a35a78c5eeb078fa960/setup.py\", line 48, in run\n",
      "  \u001b[31m   \u001b[0m     build_models(target_dir)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/53/lfhrj5t92lb1ltnby1j6jf000000gn/T/pip-install-jzutxkvv/fbprophet_1834d5c075da4a35a78c5eeb078fa960/setup.py\", line 36, in build_models\n",
      "  \u001b[31m   \u001b[0m     from fbprophet.models import StanBackendEnum\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/53/lfhrj5t92lb1ltnby1j6jf000000gn/T/pip-install-jzutxkvv/fbprophet_1834d5c075da4a35a78c5eeb078fa960/fbprophet/__init__.py\", line 8, in <module>\n",
      "  \u001b[31m   \u001b[0m     from fbprophet.forecaster import Prophet\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/53/lfhrj5t92lb1ltnby1j6jf000000gn/T/pip-install-jzutxkvv/fbprophet_1834d5c075da4a35a78c5eeb078fa960/fbprophet/forecaster.py\", line 17, in <module>\n",
      "  \u001b[31m   \u001b[0m     from fbprophet.make_holidays import get_holiday_names, make_holidays_df\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/53/lfhrj5t92lb1ltnby1j6jf000000gn/T/pip-install-jzutxkvv/fbprophet_1834d5c075da4a35a78c5eeb078fa960/fbprophet/make_holidays.py\", line 14, in <module>\n",
      "  \u001b[31m   \u001b[0m     import fbprophet.hdays as hdays_part2\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/53/lfhrj5t92lb1ltnby1j6jf000000gn/T/pip-install-jzutxkvv/fbprophet_1834d5c075da4a35a78c5eeb078fa960/fbprophet/hdays.py\", line 924, in <module>\n",
      "  \u001b[31m   \u001b[0m     class TU(Turkey):\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/ken/Library/Caches/pypoetry/virtualenvs/assignment2-Of0dlyWH-py3.9/lib/python3.9/site-packages/holidays/registry.py\", line 176, in __init__\n",
      "  \u001b[31m   \u001b[0m     raise TypeError(\n",
      "  \u001b[31m   \u001b[0m TypeError: This is a python-holidays entity loader class. For entity inheritance purposes please import a class you want to derive from directly: e.g., `from holidays.countries import Entity` or `from holidays.financial import Entity`.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for fbprophet\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for fbprophet\n",
      "Failed to build fbprophet\n",
      "\u001b[31mERROR: Could not build wheels for fbprophet, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels,matplotlib,xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ARIMA_model = ARIMA(train_data[\"revenue\"], order=(0,1,0))\n",
    "ARIMA_fit = ARIMA_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Forecast on the validating set\n",
    "forecast_steps = len(valid_data)\n",
    "forecast = ARIMA_fit.get_forecast(steps=forecast_steps)\n",
    "forecast_values = forecast.predicted_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 20194.142971790858\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = np.sqrt(mean_squared_error(valid_data['revenue'], forecast_values))\n",
    "print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. XGBoost model with hyperparamaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 19476.41005217665\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "X_train,y_train = train_data[['lag_1']], train_data['revenue']\n",
    "X_val,y_val = valid_data[['lag_1']], valid_data['revenue']\n",
    "\n",
    "XGB = XGBRegressor(n_estimators=100, learning_rate=0.04, max_depth=2)\n",
    "XGB_fit=XGB.fit(X_train, y_train)\n",
    "# Make predictions on the validating set\n",
    "y_preds = XGB_fit.predict(X_val)\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_preds))\n",
    "print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. XGBoost model with optimal hyperparamaters and lags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 9323.332102272147\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "df_cleaned = df_train_grouped.copy()\n",
    "df_cleaned['day_of_month'] = df_cleaned['date'].dt.day\n",
    "df_cleaned['month_of_year'] = df_cleaned['date'].dt.month\n",
    "df_cleaned['day_of_week'] = df_cleaned['date'].dt.dayofweek\n",
    "\n",
    "#Set up lag\n",
    "lag = 34\n",
    "for i in range(1, lag + 1):\n",
    "    df_cleaned[f'lag_{i}'] = df_cleaned['revenue'].shift(i)\n",
    "#Drop na after lag\n",
    "df_cleaned = df_cleaned.dropna()\n",
    "\n",
    "#Spliting data again\n",
    "index = int(len(df_cleaned) * 0.8)\n",
    "train_data = df_cleaned.drop(columns=['date','is_event']).iloc[:index]\n",
    "valid_data = df_cleaned.drop(columns=['date','is_event']).iloc[index:]\n",
    "\n",
    "#Fit model\n",
    "XGB = XGBRegressor(n_estimators=100, learning_rate=0.04, max_depth=2,random_state=42)\n",
    "X_train = train_data.drop('revenue', axis=1)\n",
    "y_train = train_data['revenue']\n",
    "XGB_lag_fit=XGB.fit(X_train, y_train)\n",
    "\n",
    "#Predict validate data\n",
    "X_val = valid_data.drop('revenue', axis=1)\n",
    "y_val = valid_data['revenue']\n",
    "y_preds = XGB_lag_fit.predict(X_val)\n",
    "\n",
    "#Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_preds))\n",
    "print(f'RMSE: {rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../models/forecasting/XGBoost.joblib']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(XGB_lag_fit,'../../models/forecasting/XGBoost.joblib')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "3IwbDesTs-dr",
    "Vf73A1HmK1v5",
    "zQvGUYHjpdIc",
    "_NCwQQFkU3v5",
    "P4POxjz4Oi6W",
    "TrAHjeLjOBQQ"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
